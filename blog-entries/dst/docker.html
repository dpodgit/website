<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="author" content="David O'Dwyer">

<link rel="stylesheet" href="./style.css" />

<title>David O'Dwyer's Blog</title>
</head>

<body>
<h1 id="Why%20Docker?">Why Docker?</h1>

<p>Objects of computer:</p>

<ul>
<li>90s: Mainframe to PC</li>
<li>00s: Baremetal to Virtual</li>
<li>10s: Datacentre to Cloud</li>
<li>Now: Host to Container (Serverless)</li>
</ul>

<p>Why Docker: Faster:</p>

<ul>
<li>Development</li>
<li>Building</li>
<li>Testing</li>
<li>Deployment</li>
<li>Updates</li>
<li>Recovery</li>
</ul>

<p>Without containers, lots of types of applications – front&#47;back end, workers, user DBs, analytics DBs, etc., – that all must work together and all of which have their own dependencies; which might run on different OSs; which might run in different dev&#47;prod, local&#47;cloud environments, etc. Complicated.</p>

<p>With Docker, all of these applications are packaged the same way: in containers.</p>

<p>Reason for enthusiastic uptake of Docker and containerisation:</p>

<ul>
<li>application does not need to be rewritten as a prerequisite. It is just a different way of running, packaging, and moving around one&#39;s architecture the application. </li>
<li>saving in infrastructure: fewer VMs, fewer CPUs, better CPU utilization, etc.</li>
</ul>

<h1 id="The%20Best%20Way%20to%20Set%20Up%20Docker%20for%20Your%20OS">The Best Way to Set Up Docker for Your OS</h1>

<h2 id="Docker%20Editions">Docker Editions</h2>

<p>Three major types of installs:</p>

<ol start="1">
<li>Direct: Native support on kernel &#47; OS (Linux, RPi, Windows Server 2016, etc.) 

<ul>
<li>Different per distro</li>
<li>Don&#39;t use default package

<ul>
<li>For latest edge release: <code>curl -sSL https:&#47;&#47;get.docker.com&#47; | sh</code></li>
<li>See <em>store.docker.com</em> for instructions on installs for each distro; Debian-based &#47; Fedora- or RH-based distributions (apt and yum package managers).

<ul>
<li>RHEL officially only supports Docker EE (paid), but can install CentOS&#8217; Docker CE. </li>
</ul></li>
</ul></li>
</ul></li>
<li>Mac&#47;Win: Non-native support; includes suite of tools (inc. GUI, settings, preferences)

<ul>
<li>OSX &#47; Win10: small VM started to run containers in, transparently.</li>
<li>Homebrew-installed Docker is CLI only: useful to remote-talk to server.</li>
</ul></li>
<li>Cloud: AWS &#47; Azure &#47; Google

<ul>
<li>Docker installed on a Linux machine, with additional features specific to that cloud platform.</li>
<li>Example: Docker for AWS includes CloudFormation template, persistent storage options for storing DBs, features that automatically update elastic load balancers, etc.</li>
<li>Docker on Linux may not work for unlisted distros such as Amazon Linux, Linode Linux, etc.</li>
</ul></li>
</ol>

<p>Note: Don&#39;t use the pre-installed setups (w&#47; Digital Ocean, Linode, etc.) because Docker moves fast and one wants the latest version of Docker. </p>

<p>CE vs. EE; Stable vs. Edge</p>

<ul>
<li>Community (free), Enterprise (paid)

<ul>
<li>EE: much longer support lifecycles. </li>
</ul></li>
<li>&#8220;Edge&#8221; = Beta; monthly release; only supported until the following edge release (1 month).</li>
<li>&#8220;Stable&#8221;: released once &#47; quarter; 4 months support (1 month into subsequent stable release)</li>
</ul>

<h3 id="Linux%20Install">Linux Install</h3>

<ul>
<li>Find the correct version in the Docker store (e.g. a certain version of MintOS is based on, e.g. Ubuntu 16.4)</li>
<li>Or use the script at get.docker.com: <code>curl -fsSL get.docker.com -o get-docker.sh</code> (prompts for password)</li>
<li>To run Docker commands without sudo: <code>sudo usermod aG docker &#60;user-with-root&#62;</code>: add the user account to the docker group on our system

<ul>
<li>Allows user to run a docker container that could then have root permissions on the host.</li>
<li>This does not work with RHEL or Centos or Fedora: you must be root or run sudo for every Docker command.

<ul>
<li>If you get the &#8220;Got permission denied while trying to connect to the Docker daemon socket [&#8230;]&#8221;, this is saying as much.</li>
</ul></li>
</ul></li>
<li>Docker Machine and Docker Compose (each a single binary) do not come packaged with Linux-based installs (as they do with Mac or Win).

<ul>
<li>See &#8220;Install Machine&#8221; and &#8220;Install Compose&#8221; in the Docker Docs. </li>
<li>Alternatively, the latest versions will certainly be at github.com&#47;docker&#47;compose-or-releases&#47;releases</li>
<li>Must <code>chmod +x</code> both docker-machine and docker-compose, and they each should live in <code>&#47;usr&#47;local&#47;bin</code></li>
</ul></li>
<li>Must then periodically check for updates for each.</li>
</ul>

<h2 id="Docker%20for%20Mac%20Setup%20and%20Tips">Docker for Mac Setup and Tips</h2>

<p>Docker &#62; Preferences &#62; </p>

<ul>
<li>General

<ul>
<li>Can easily switch between stable and edge versions (if, e.g., presume a bug in an edge)</li>
</ul></li>
<li>File Sharing

<ul>
<li>To work with code that is on a host machine (i.e. in Docker) – &#8220;bind mounting&#8221; – the code needs to be listed in one of the volumes &#47; OS dir on this tab.</li>
</ul></li>
<li>Advanced

<ul>
<li>Assign CPUs and RAM to the background VM. Example 2 CPUs and 4GB Ram.</li>
<li>These are <em>maximums</em> for Docker.</li>
</ul></li>
</ul>

<p>Section commands:</p>

<ul>
<li><p><code>docker version</code></p></li>
<li><p><code>docker</code></p></li>
<li><p><code>docker pause</code></p></li>
</ul>

<h1 id="Creating%20and%20Using%20Containers%20Like%20a%20Boss">Creating and Using Containers Like a Boss</h1>

<ul>
<li>The Docker &#8220;Server&#8221; (i.e from <code>docker version</code>) is also called the &#8220;Engine&#8221;. It&#39;s a daemon. </li>
<li>Command line calls interact with the server, and return its values in addition to its client values.</li>
<li>Ideally, the client and server should be the same version, but they need not be.</li>
</ul>

<h2 id="Check%20Our%20Docker%20Install%20and%20Config">Check Our Docker Install and Config</h2>

<ul>
<li><p><code>docker version</code>: check the Docker server version </p></li>
<li><p><code>docker info</code> lists most of the config &#38; status values of the engine</p></li>
<li><p><code>docker</code> incomplete list of docker commands </p></li>
</ul>

<p>Docker commands are broken into </p>

<ol start="1">
<li>Management commands</li>
<li>Sub-commands. </li>
</ol>

<p>Syntax <code>docker &#60;mgmt-cmd&#62; &#60;sub-cmd&#62;</code>.</p>

<p>Can run <code>docker --help</code>, <code>docker &#60;mgmt-cmd&#62; --help</code>, <code>docker &#60;mgmt-cmd&#62; &#60;sub-cmd&#62; --help</code> for varying levels of specific help.</p>

<p>Management commands:</p>

<ul>
<li>builder</li>
<li>config</li>
<li>container </li>
<li>context<br/></li>
<li>image<br/></li>
<li>network</li>
<li>node<br/></li>
<li>plugin</li>
<li>secret</li>
<li>service</li>
<li>stack </li>
<li>swarm</li>
<li>system</li>
<li>trust </li>
<li>volume</li>
</ul>

<h2 id="Starting%20a%20Nginx%20Web%20Server">Starting a Nginx Web Server</h2>

<p><strong>Docker Image</strong>: is the binaries, libraries, and source code that make up an app.</p>

<p><strong>Docker Container</strong>: an instance of an images, running as a proces. Multiple containers can run off a single image.</p>

<p>We&#39;ll use nginx as an example image.</p>

<ul>
<li><p><code>docker container run --publish 80:80 nginx</code></p>

<ul>
<li><code>docker container run</code> looked for a downloaded nginx image from Docker Hub, and started a new container from that image</li>
<li><code>publish [host-port : container-port]</code> opened port 80 on the host IP and route traffic to port 80 on the container.</li>
</ul></li>
<li><p><code>docker container run --publish 80:80 --detach nginx</code></p>

<ul>
<li><code>--detach</code> run in the background. Short: <code>-d</code>.</li>
<li>It returns a unique container ID.</li>
<li>Each container gets a unique ID.</li>
<li>Each container also gets a name, which, if not specified, is randomly generated.</li>
</ul></li>
<li><p><code>docker container ls</code>: list running containers</p></li>
<li><p><code>docker container ls -a</code>: list all (not just running) containers</p></li>
<li><p><code>docker container stop 690</code>: (where 690 are the first few digits, enough for uniqueness, of the docker id)</p></li>
<li><p><code>docker container run --publish 80:80 --detach --name webhost nginx</code></p>

<ul>
<li><code>--name</code> specifies name</li>
</ul></li>
<li><p><code>docker container logs webhost</code>: (where &#8216;webhost&#8217; is the name of the container)</p></li>
<li><p><code>docker container logs --help</code> for the additional options (e.g. period)</p></li>
<li><p><code>docker container top webhost</code>: lists processes running inside the specified container (&#8220;webhost&#8221;). </p>

<ul>
<li>Lists Master and spawned processes.</li>
</ul></li>
<li><p><code>docker container rm 63f 690</code>: delete specified <em>non-running</em> containers</p>

<ul>
<li>If a running container is listed, the non-running are deleted and an error is thrown for the running.</li>
<li>Can run <code>docker container stop &#60;running-con-id&#62; &#38;&#38; docker container rm &#60;now-stopped-con-id&#62;</code></li>
<li>Or <code>docker container rm -f &#60;running-con-id&#62;</code></li>
</ul></li>
</ul>

<hr/>

<p>Notes on <code>run</code>:</p>

<ul>
<li>On <code>run</code>, Docker will look for the specified image locally; will lookup on remote if not (default is Docker Hub).

<ul>
<li>By default, Docker downloads the lastest version (nginx:latest).</li>
</ul></li>
<li>Container Creation: the actual <code>run</code>-ing of the image does not involve <em>copying</em> the image; rather, it starts a &#8220;new layer of changes&#8221; &#8220;on top&#8221; of that image</li>
<li>It then customises the networking (virtual IP on private network w&#47;in Docker engine).</li>
<li>It then applies any of the options we specified (e.g. opening port 80). </li>
<li>Finally, the container is started by using the CMD in the image Dockerfile.</li>
</ul>

<h2 id="Container%20VS.%20VM:%20It&amp;#39;s%20Just%20a%20Process">Container VS. VM: It&#39;s Just a Process</h2>

<p>Containers arent virtal machines. They are processes. Their PID is exposed as per any process (on Linux, not MacOS or MS due to virtualisation layer).</p>

<ul>
<li><p><code>docker run --name mongo -d mongo</code></p></li>
<li><p><code>docker top mongo</code>: same as UNIX <code>top</code></p>

<ul>
<li>The processes listed could equally be seen from the OS, if using Linux, albeit with different PID due to security layer. </li>
</ul></li>
<li><p><code>docker stop mongo</code></p></li>
<li><p><code>docker start mongo</code></p></li>
</ul>

<h2 id="New%20from%20Assignment:%20Manage%20Multiple%20Containers">New from Assignment: Manage Multiple Containers</h2>

<ul>
<li><code>docker container run -d -p 3306:3306 --name db -e MYSQL_RANDOM_ROOT_PASSWORD=yes MYSQL_RANDOM_ROOT_PASSWORD</code>

<ul>
<li>The <code>-e</code> or <code>--env</code> option is used to pass variables to a container on creation.</li>
</ul></li>
</ul>

<h2 id="What&amp;#39;s%20Going%20On%20In%20Containers:%20CLI%20Process%20Monitoring">What&#39;s Going On In Containers: CLI Process Monitoring</h2>

<ul>
<li><p><code>docker container top mysql</code>: view processes</p></li>
<li><p><code>docker container inspect mysql</code>: view env metadata for the container, returned as JSON array.</p></li>
<li><p><code>docker container stats [container]</code>: streaming view of live performance data</p></li>
</ul>

<h2 id="Getting%20a%20Shell%20Inside%20Containers:%20No%20Need%20for%20SSH">Getting a Shell Inside Containers: No Need for SSH</h2>

<ul>
<li><code>docker container run -it --name proxy nginx bash</code>: 

<ul>
<li><code>-i</code> interaction (keep the session open to run more commands) </li>
<li><code>-t</code> pseudo tty; </li>
<li><code>bash</code> specifies an alternative command to run on start-up (the image - here, nginx – has its default command, this overwrites).</li>
</ul></li>
</ul>

<p>Containers only run for a long as the COMMAND run at start-up runs. Above, <code>bash</code> was the optional command provided after the image name. Thus, when we exit this interactive shell the container is Stopped.</p>

<ul>
<li><code>docker container run -it ubuntu</code>

<ul>
<li>Ubuntu&#39;s default CMD is bash, so not necessary to specify it.</li>
</ul></li>
</ul>

<p>Downloading something like Ubuntu will install a very minimal version of the OS. </p>

<p>If you were to <code>apt get</code> in this Ubuntu container, install software, it would have these installs after and stop and start. Creating a new container from the Ubuntu image would not have these packages.</p>

<ul>
<li><code>docker container start -ai ubuntu</code>

<ul>
<li><code>-ai</code> for starting an <em>existing</em> container.

<ul>
<li><code>--attach --interactive</code></li>
</ul></li>
</ul></li>
</ul>

<hr/>

<p>The <code>exec</code> option runs an additional process on an existing running container, and does not affect the root process on the daemon. It allows you to &#8220;jump into&#8221; the container, do something, and exit without stopping the container.  </p>

<ul>
<li><code>docker container exec -it mysql bash</code></li>
<li><code>docker container exec -it my-nginx-instance bash</code></li>
</ul>

<p>Alpine Linux is a very small (5mb), security-focused distribution.
Package manager is <code>apk</code></p>

<ul>
<li><p><code>docker container run -it alpine bash</code></p>

<ul>
<li>This will fail as <code>bash</code> <em>is not</em> installed in Alpine.</li>
</ul></li>
<li><p><code>docker container run -it alpine sh</code> (sh is an available shell)</p></li>
</ul>

<hr/>

<p>Side note. The <code>ps</code> command if not included in an image can be installed with <code>apt-get update &#38;&#38; apt-get install -y procps</code>.</p>

<h2 id="Docker%20Networks:%20Concepts%20for%20Private%20and%20Public%20Comms%20in%20Containers">Docker Networks: Concepts for Private and Public Comms in Containers</h2>

<p>Each container is connected to a private virual network. The default is called &#8220;bridge&#8221;.</p>

<p>Each virtual network routes through NAT firewall on the host IP; Docker daemon configures the host IP address on its default interface so that the containers can get out to the public internet. </p>

<p>Containers on a virtual network can communication without the <code>-p</code> option.</p>

<p>Best practice is to create a new virtual network for each app. For example, an app using mysql, apache, and php should be on the same network so that they can communicate without needing to open their ports to the rest of the physical network.</p>

<p>The defaults are modifiable:</p>

<ul>
<li>A container can be attached to more than one virtual network (or none), similarly to how computers can have more than one NIC.</li>
<li>Can skip any of the virtual network configuration and just use <code>--net=host</code>, which will result in losing some of the containerisation benefits, but may be required.</li>
<li>Among the Docker plugins are different Docker network drivers, which can offer different options.</li>
<li>etcetc</li>
</ul>

<p>Note there are &#8220;exposed ports&#8221; that are listed in the Docker file, which are exposed in the virtual network, but are not public (as <code>-p</code> would do). These container ports are listed with a <code>docker container ls</code>. Of the form <code>0.0.0.0:80-&#62;80&#47;tcp</code>.</p>

<hr/>

<ul>
<li><p><code>docker container run -p 80:80 --name webhost -d nginx</code></p></li>
<li><p><code>docker container port webhost</code>: nice format of the HOST:CONTAINER port map, for all ports forwarding into container.</p></li>
</ul>

<p>The IP address of the container is, by default, not the same as that of the host. </p>

<ul>
<li><code>docker container inspect --format &#39;{{ .NetworkSettings.IPAddress }}&#39; webhost</code>: a cleaner, more consistent alternative to grep-ing on the result. It references the nodes of the JSON.</li>
</ul>

<h2 id="Docker%20Networks:%20CLI%20Management%20of%20Virtual%20Networks">Docker Networks: CLI Management of Virtual Networks</h2>

<ul>
<li><code>docker network ls</code>: list the virtual networks</li>
</ul>

<p>By default there are <em>bridge</em>, <em>host</em> and <em>none</em> networks.</p>

<ul>
<li><p>Bridge: the default network that bridges through the NAT firewall behind the Host IP.</p></li>
<li><p>Host: a special network that skips the virtual networking of Docker, and attaches the network directly to the host&#39;s interface. 

<ul>
<li>Pros: in certain situations can improve the performance of high throughput networking and get around a few other issues with specific software</li>
<li>Cons: prevents security boundaries of the containerisation from protecting the interface of that container</li>
</ul></p></li>
<li><p>None: removes eth0 and only leaves you with localhost interface in container.</p></li>
<li><p><code>docker network inspect bridge</code>: inspect (i.e. metadata) of the network &#8220;bridge&#8221;</p>

<ul>
<li>Lists the containers attached to that network + the IPs</li>
<li>The IPAM config shows the subnet default and gateway 

<ul>
<li>Default subnet: 172.17.0.0&#47;16</li>
</ul></li>
</ul></li>
<li><p><code>docker network create --help</code>: look at the advanced params that can be set if needed.</p></li>
<li><p><code>docker network create my_app_net</code>: create the network &#8220;my_app_net&#8221;</p>

<ul>
<li>Default driver when creating a network is &#8220;bridge&#8221;.

<ul>
<li>create a local virtual subnet with IPs around 172.17, incrememting as more created.</li>
<li>a simple driver.</li>
</ul></li>
<li>A different driver can be specified with <code>--driver</code></li>
</ul></li>
<li><p><code>docker container run -d --network my_app_net nginx</code>: create a container on the new network. </p></li>
</ul>

<hr/>

<ul>
<li><p><code>docker network --help</code></p></li>
<li><p><code>docker container connect &#60;network-id&#62; &#60;container-id&#62;</code> (remember order: from the network, the container)</p>

<ul>
<li>Connect an existing container to an existing v.network

<ul>
<li>If the container is already part of another network (e.g. bridge) it will now be attached to two networks.</li>
</ul></li>
<li><code>docker network connect</code> dynamically creates a NIC in a container on an existing virtual network. </li>
</ul></li>
<li><p><code>docker container disconnect &#60;network-id&#62; &#60;container-id&#62;</code>: disconnect containter from network.</p></li>
</ul>

<hr/>

<p>The default security this entails:</p>

<ul>
<li>App front and backends are on the same Docker network: no overexposing of ports.</li>
<li>The inter-communication of the containers never leaves the host</li>
<li>All external exposed ports are closed by default on the host; must use <code>-p</code> to expose.</li>
</ul>

<h2 id="Docker%20Networks:%20DNS%20and%20How%20Containers%20Find%20Each%20Other">Docker Networks: DNS and How Containers Find Each Other</h2>

<p>Containers are too dynamic to rely on IP addresses for communication. Also using Static IPs is anti-pattern. Avoid it.</p>

<p>Docker uses container names as an equivalent to hostnames. It has a built in DNS server, which containers use by default.</p>

<p>Creation of a new network – not using the default bridge network – has <em>automatic DNS resolution</em> as a feature for all the containers on that network, w&#47;r&#47;t all the other containers on that network. Again, DNS is using container names.</p>

<p><strong>Note:</strong> the default bridge network does <em>not</em> have DNS server built-in by default. You can use the <code>--link</code> option to manually specify links between containers in that default bridge network. </p>

<p>Syntax: <code>--link &#60;name or id&#62;:alias</code></p>

<p>It is much easier, however, to create a new network for your apps to avoid this. This is simplified by Docker Compose, which automatically creates new virtual networks whenever you start up an app.</p>

<h2 id="New%20from%20Assignment:%20Using%20Containers%20for%20CLI%20Testing">New from Assignment: Using Containers for CLI Testing</h2>

<ul>
<li><code>docker container run --rm -it centos:7 bash</code>

<ul>
<li>The <code>--rm</code> option with run: Automatically remove the container when it exits.</li>
</ul></li>
</ul>

<h2 id="Assignment%20Answers:%20DNS%20Round%20Robin%20Testing;%20DNS%20Aliases">Assignment Answers: DNS Round Robin Testing; DNS Aliases</h2>

<p>DNS Round Robin: You can have 2 different hosts with DNS aliases that respond to the same DNS name. E.g. google.com has multiple server IPs and DNS records behind the domain name.</p>

<p>&#8220;Ever since Docker Engine 1.11, we can have multiple containers on a created network respond to the same DNS address.&#8221; If we create a custom network, we can assign an alias so that multiple containers can respond to the same DNS name.</p>

<p>Aliases are assigned seperate to container names with the <code>docker container run</code> option <code>--network-alias</code>.</p>

<p>Example use: </p>

<ul>
<li>Not possible to add multiple containers with the same name</li>
<li>Want to have the same app installed twice (e.g Dev, Test) on the same Docker server.</li>
<li>You need to resolve DNS on the networks, while having in each installation something called &#8220;search&#8221;.</li>
<li>Solution: add aliases to containers, and they can respond as a DNS round robin would.</li>
</ul>

<h1 id="Container%20Images,%20Where%20To%20Find%20Them%20and%20How%20To%20Build%20Them">Container Images, Where To Find Them and How To Build Them</h1>

<p>An image is: app binaries and dependencies. It is not a complete OS: No kernel, no kernel modules (e.g. drivers). The host provides the kernel: this is a main difference between containers and VMs.</p>

<h2 id="The%20Mighty%20Hub:%20Using%20Docker%20Hub%20Registry%20Images">The Mighty Hub: Using Docker Hub Registry Images</h2>

<p>http:&#47;&#47;hub.docker.com</p>

<p>Non official images are of the form: account-name&#47;image-repo-name. Official images do not have the account-name.</p>

<p>Images aren&#39;t named, they are tagged, and an image can have multiple tags. A tag is not necessarily a version (and possibly patch) number. An image may have more than one tag.</p>

<p>All tags will refer to the same image SHA. The &#8220;latest&#8221; tag refers to the &#8220;latest version&#8221;, as opposed to the &#8220;latest commit&#8221;. Docker run does not check for a newer version of an image if one is already cached locally. In any case, &#8220;latest&#8221; is best avoided for precise specifications because it will of course change.</p>

<p>The most precise is image release-version-patch. Specifying release-version would default to the latest patch.</p>

<p>The default &#47; latest images come with a base image of Jesse (Debian distribution). Distinction from the Alpine verions.</p>

<p>The <code>IMAGE ID</code> is based upon the SHA of an image. Pulling images with equivalant tags will show up as distinct with a <code>docker image ls</code>, but with the same <code>IMAGE ID</code>. They are not distinct files &#47; packages.</p>

<ul>
<li><code>docker pull nginx</code>: download the image

<ul>
<li><code>docker pull nginx:1.11.9</code>: download specific version &#38; patch</li>
</ul></li>
</ul>

<h2 id="Images%20and%20Their%20Layers:%20Discover%20the%20Image%20Cache">Images and Their Layers: Discover the Image Cache</h2>

<p>Every image starts with a blank layer – called &#8220;scratch&#8221; – and every set of changes after that on the file system in the image is another layer. Every layer has its own unique SHA. This is called the &#8220;Union File System&#8221;.</p>

<p>Image history is a history of the image layers. The Nginx one looks like (<code>docker history nginx:latest</code>):</p>

<pre><code>IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
ae2feff98a0c        2 weeks ago         &#47;bin&#47;sh -c #(nop)  CMD ["nginx" "-g" "daemon…   0B                  
&#60;missing&#62;           2 weeks ago         &#47;bin&#47;sh -c #(nop)  STOPSIGNAL SIGQUIT           0B                  
&#60;missing&#62;           2 weeks ago         &#47;bin&#47;sh -c #(nop)  EXPOSE 80                    0B                  
&#60;missing&#62;           2 weeks ago         &#47;bin&#47;sh -c #(nop)  ENTRYPOINT ["&#47;docker-entr…   0B                  
&#60;missing&#62;           2 weeks ago         &#47;bin&#47;sh -c #(nop) COPY file:0fd5fca330dcd6a7…   1.04kB              
&#60;missing&#62;           2 weeks ago         &#47;bin&#47;sh -c #(nop) COPY file:0b866ff3fc1ef5b0…   1.96kB              
&#60;missing&#62;           2 weeks ago         &#47;bin&#47;sh -c #(nop) COPY file:e7e183879c35719c…   1.2kB               
&#60;missing&#62;           2 weeks ago         &#47;bin&#47;sh -c set -x     &#38;&#38; addgroup --system -…   63.7MB              
&#60;missing&#62;           2 weeks ago         &#47;bin&#47;sh -c #(nop)  ENV PKG_RELEASE=1~buster     0B                  
&#60;missing&#62;           2 weeks ago         &#47;bin&#47;sh -c #(nop)  ENV NJS_VERSION=0.5.0        0B                  
&#60;missing&#62;           2 weeks ago         &#47;bin&#47;sh -c #(nop)  ENV NGINX_VERSION=1.19.6     0B                  
&#60;missing&#62;           3 weeks ago         &#47;bin&#47;sh -c #(nop)  LABEL maintainer=NGINX Do…   0B                  
&#60;missing&#62;           3 weeks ago         &#47;bin&#47;sh -c #(nop)  CMD ["bash"]                 0B                  
&#60;missing&#62;           3 weeks ago         &#47;bin&#47;sh -c #(nop) ADD file:3a7bff4e139bcacc5…   69.2MB   
</code></pre>

<p>Because each layer is unique – and layers are bundled into images – the same layer (e.g. a Ubuntu version) can be used in multiple images - and is stored only once. In other words the layers – unique versions of an app – are downloaded once and reused across different images.</p>

<p>When running a container from a image, Docker creates a new read&#47;write layer for that container on top of the image. </p>

<p>If looking at file system in a container, it looks like regular file system; but underneath, the storage driver that&#39;s used by Docker is layering all of the changes atop eachother. The read&#47;write layer constituting a container will be on top of a read-only base image. The container file space is only the differencing of what has happened on that live contaniner and what is on the base image.</p>

<p><strong>Copy on Write</strong></p>

<p>Images are read-only. Containers and read&#47;write layers added on top of the image.</p>

<p>If, in a container, you were to change a file in the image: &#8220;copy on write&#8221;. The file system copies that file from the image into the container layer. Thus, the container is just its running process and the files that are different to its base image.</p>

<p><code>docker image inspect &#60;image-tag&#62;</code>: display an images metadata</p>

<h2 id="Image%20Tagging%20and%20Pushing%20to%20Docker%20Hub">Image Tagging and Pushing to Docker Hub</h2>

<p>Usage:  <code>docker image tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]</code></p>

<p>Create a tag <code>TARGET_IMAGE</code> that refers to <code>SOURCE_IMAGE</code></p>

<p>The :TAG is optional; if not specified it defaults to &#8220;latest&#8221;. This should be assigned to the newest, stable version; but this is just convention, as any old image could be retagged as &#8216;latest&#8217;.</p>

<hr/>

<p>Images don&#39;t technically have a name. They are referred to by 3 different pieces of information (in addition to the IMAGE ID): <code>&#60;user&#62;&#47;&#60;repo&#62;:&#60;tag&#62;</code></p>

<p>Official repos live at the &#8220;root namespace&#8221; of the registry, and they don&#39;t need an account &#47; user name in front of the repo name.</p>

<p>&#8216;Tags&#8217; are not quite versions and not quite branches, but are a lot like git tags: a point to a specific image commit. On Docker Hub, if you see tags grouped such as <code>5.7.17</code>, <code>5.7</code>, <code>5</code>: they have the same image ID.</p>

<hr/>

<ul>
<li><code>docker image tag -- help</code></li>
</ul>

<hr/>

<h3 id="How%20to%20make%20new%20labels%20(and%20duplicate%20repos%20on%20Docker%20Hub)">How to make new labels (and duplicate repos on Docker Hub)</h3>

<p>Could make one&#39;s own Dockerfile and custom image, but existing images can also be re-tagged. For example:</p>

<ul>
<li><code>docker image tag nginx bretfisher&#47;nginx</code>

<ul>
<li><code>nginx</code> is the image we want to give a new tag to</li>
<li><code>bretfisher&#47;nginx</code> is the new tag given to it.</li>
</ul></li>
</ul>

<p>Usage:  <code>docker image tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]</code></p>

<p>The :TAG is optional; if not specified it defaults to &#8220;latest&#8221;. This should be assigned to the newest, stable version; but this is just convention, as any old image could be retagged as &#8216;latest&#8217;.</p>

<p>The above will result in an existing Image ID with a new &#8216;REPOSITORY&#8217; description of user-name&#47;repo that <em>does not yet exist on Docker Hub</em>. The image can be pushed to Hub by:</p>

<ol start="1">
<li>Logging into Docker Hub: <code>docker login [server]</code>

<ul>
<li>Without specifying <code>server</code>, Docker defaults to logging into Hub.</li>
<li>This can be overwritten by adding a server URL.</li>
<li>The <code>login</code> command also writes to a file that stores an auth key, allowing the CLI to access Docker Hub as the logged in user. For MacOS it&#39;s stored in Keychange. For linux, it&#39;s stored in <code>.docker&#47;config.json</code>.</li>
<li><code>docker logout</code> to remove the auth key.</li>
</ul></li>
<li>Pushing: <code>docker image push bretfisher&#47;nginx</code>

<ul>
<li>As an example of also adding a tag: <code>docker image tag nginx bretfisher&#47;nginx:testing</code></li>
</ul></li>
</ol>

<p>To make a private repo:</p>

<ul>
<li>Create on Hub first</li>
<li>Then push to it</li>
</ul>

<h2 id="Building%20Images:%20The%20Dockerfile%20Basics">Building Images: The Dockerfile Basics</h2>

<p>The default name is &#8220;Dockerfile&#8221; – with a capital D. From the command line, the <code>-f</code> option can be used to specify some other file than the default (e.g. <code>docker build -f &#60;some-dockerfile&#62;</code>.</p>

<ul>
<li><code>cd dockerfile-sample-1</code></li>
<li><code>vim Dockerfile</code></li>
</ul>

<p>The default name is capital-d &#8220;Dockerfile&#8221;.</p>

<p>?: You can use a diiferent file than the default with option-f: e.g.: <code>docker build -f some-dockerfile</code></p>

<p>Element (&#8220;Stanzas&#8221;) of Docker script:</p>

<p>Note that each stanza is a layer of a Docker image. Thus order matters.</p>

<ul>
<li><code>FROM</code>: normally a minimal distribution (now often Alpine); required field. 

<ul>
<li>A main benefit is being able to use their package distribution systems.</li>
<li><code>FROM</code> can be an OS image (e.g. <code>debian:jessie</code>) or an image (e.g. <code>nginx:latest</code>)</li>
</ul></li>
<li><code>ENV</code>: a way to set key:val environment variables; the main way we set vars in containers for building &#38; running containers.</li>
<li><code>RUN</code>: execute shell commands, as container is being built (installs, unzips, file edits, etc.)

<ul>
<li><code>RUN</code> command can also execute shell scripts that you have previously copied in; or any commands you can access from w&#47;in the container at that point in time.</li>
<li>Best practice to chain with <code>&#38;&#38;</code> so that commands are fit into one single layer: saves time &#38; space.</li>
<li>In the <em>Dockerfile-sample-1</em> file, the second <code>RUN</code> block links the container (nginx)&#39;s log files to <code>stdout</code> and <code>stderr</code> so that Docker can capture them.</li>
</ul></li>
<li><code>EXPOSE</code>: by default no TCP or UDP ports are open inside a container. List here what to expose to the virtual network.

<ul>
<li>This does not <em>open</em> these ports; that&#39;s what the <code>run -p</code> command does.</li>
</ul></li>
<li><code>CMD</code>: required parameter; is the final command that will be run everytime a new container is launched from the image, or every time a stopped container is restarted.</li>
<li><code>WORKDIR</code>: sets the path for all future Dockerfile lines. It&#39;s like a <code>[[ -d DIR ]] &#38;&#38; cd DIR || mkdir -p DIR &#38;&#38; cd DIR</code>

<ul>
<li>Use a seperate WORKDIR standza whenever changing directories. Don&#39;t use <code>cd</code> in a <code>RUN</code> stanza.</li>
</ul></li>
<li><code>COPY</code>: copy source code from local machine &#47; build server into container images.</li>
</ul>

<p><strong>Note:</strong> the required stanzas (e.g. <code>CMD</code>) might be <em>inherited</em> from an Docker file brought in in the <code>FROM</code> stanza. See dockerfile-sample-2 as example.</p>

<p>If <code>FROM</code> is an OS, it is required; but if <code>FROM</code> is, e.g., Nginx, it itself will contain, e.g. a <code>CMD</code> stanza.</p>

<h3 id="Example%20Dockerfile:%20Druple&amp;#39;s">Example Dockerfile: Druple&#39;s</h3>

<pre><code># from https:&#47;&#47;www.drupal.org&#47;docs&#47;system-requirements&#47;php-requirements
FROM php:8.0-apache-buster

# install the PHP extensions we need
RUN set -eux; \
    \
    if command -v a2enmod; then \
        a2enmod rewrite; \
    fi; \
    \
    savedAptMark="$(apt-mark showmanual)"; \
    \
    apt-get update; \
    apt-get install -y --no-install-recommends \
        libfreetype6-dev \
        libjpeg-dev \
        libpng-dev \
        libpq-dev \
        libzip-dev \
    ; \
    \
    docker-php-ext-configure gd \
        --with-freetype \
        --with-jpeg=&#47;usr \
    ; \
    \
    docker-php-ext-install -j "$(nproc)" \
        gd \
        opcache \
        pdo_mysql \
        pdo_pgsql \
        zip \
    ; \
    \
# reset apt-mark&#39;s "manual" list so that "purge --auto-remove" will remove all build dependencies
    apt-mark auto &#39;.*&#39; &#62; &#47;dev&#47;null; \
    apt-mark manual $savedAptMark; \
    ldd "$(php -r &#39;echo ini_get("extension_dir");&#39;)"&#47;*.so \
        | awk &#39;&#47;=&#62;&#47; { print $3 }&#39; \
        | sort -u \
        | xargs -r dpkg-query -S \
        | cut -d: -f1 \
        | sort -u \
        | xargs -rt apt-mark manual; \
    \
    apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false; \
    rm -rf &#47;var&#47;lib&#47;apt&#47;lists&#47;*

# set recommended PHP.ini settings
# see https:&#47;&#47;secure.php.net&#47;manual&#47;en&#47;opcache.installation.php
RUN { \
        echo &#39;opcache.memory_consumption=128&#39;; \
        echo &#39;opcache.interned_strings_buffer=8&#39;; \
        echo &#39;opcache.max_accelerated_files=4000&#39;; \
        echo &#39;opcache.revalidate_freq=60&#39;; \
        echo &#39;opcache.fast_shutdown=1&#39;; \
    } &#62; &#47;usr&#47;local&#47;etc&#47;php&#47;conf.d&#47;opcache-recommended.ini

# https:&#47;&#47;github.com&#47;drupal&#47;drupal&#47;blob&#47;9.0.1&#47;composer.lock#L4052-L4053
COPY --from=composer:1.10 &#47;usr&#47;bin&#47;composer &#47;usr&#47;local&#47;bin&#47;

# https:&#47;&#47;www.drupal.org&#47;node&#47;3060&#47;release
ENV DRUPAL_VERSION 9.1.0

WORKDIR &#47;opt&#47;drupal
RUN set -eux; \
    export COMPOSER_HOME="$(mktemp -d)"; \
    composer create-project --no-interaction "drupal&#47;recommended-project:$DRUPAL_VERSION" .&#47;; \
    chown -R www-data:www-data web&#47;sites web&#47;modules web&#47;themes; \
    rmdir &#47;var&#47;www&#47;html; \
    ln -sf &#47;opt&#47;drupal&#47;web &#47;var&#47;www&#47;html; \
    # delete composer cache
    rm -rf "$COMPOSER_HOME"

ENV PATH=${PATH}:&#47;opt&#47;drupal&#47;vendor&#47;bin

# vim:set ft=dockerfile:
</code></pre>

<h2 id="Building%20Images:%20Running%20Docker%20Builds">Building Images: Running Docker Builds</h2>

<p>We&#39;ve written a Dockerfile, the instructions to build an image. Now, what to do with it?</p>

<p>The docker engine will run each Dockerfile stanza in succession – pulling required images – and cache each of those layers.</p>

<ul>
<li><code>docker image build -t customnginx .</code>: <code>-t</code> for &#8216;tag&#8217;

<ul>
<li>Because this image will only be used locally (no <code>push</code> to Hub), do not need to use Hub account name.</li>
<li><code>.</code> after tag: specify where to build, i.e. pwd</li>
</ul></li>
</ul>

<p>In the output to the build, you&#39;ll notice a hash after each step (stanza execution). This is a hash in the build cache, so that next time the image is built, if this line hasn&#39;t changed in the Dockerfile, it will not be re-run. In these subsequent builds, the build output will read &#8220;Using cache&#8221;.</p>

<p>NB: <em>After</em> a change is detected in a stanza, every stanza after that must be rebuilt. Another factor in the importance of ordering. For example, to copy in software code at the beginning of the file, then after every change in that code, the entire Dockerfile will need to be rebuilt.</p>

<p>Top of file: things that change the least
Bottom: things that change the most</p>

<h2 id="Building%20Images:%20Extending%20Official%20Images">Building Images: Extending Official Images</h2>

<ul>
<li><code>cd dockerfile-sample-2</code></li>
<li><code>vim Dockerfile</code></li>
<li><code>docker container run -p 80:80 --rm nginx</code></li>
<li><code>docker image build -t nginx-with-html .</code></li>
<li><code>docker container run -p 80:80 --rm nginx-with-html</code></li>
<li><code>docker image ls</code></li>
<li><code>docker image tag --help</code></li>
<li><code>docker image tag nginx-with-html:latest bretfisher&#47;nginx-with-html:latest</code></li>
<li><code>docker image ls</code></li>
<li><code>docker push</code></li>
</ul>

<h2 id="Pruning">Pruning</h2>

<ul>
<li><code>docker system df</code>: see space usage</li>
<li><code>docker image prune</code>: remove &#8216;dangling&#8217; images (i.e. untagged images, those showing <code>&#60;none&#62;</code> when run <code>docker images</code>; when a new build of an image is created but not given a name)</li>
<li><code>docker image prune -a</code>: remove all unused images (i.e. not assigned to or used in a container)</li>
<li><code>docker system prune</code>: remove all unused containers, networks, images (dangling and w&#47; <code>-a</code> unreferenced) and optionally volumes.</li>
</ul>

<h1 id="Container%20Lifetime%20&amp;#38;%20Persistent%20Data:%20Volumes,%20Volumes,%20Volumes">Container Lifetime &#38; Persistent Data: Volumes, Volumes, Volumes</h1>

<h2 id="Persistent%20Data:%20Data%20Volumes">Persistent Data: Data Volumes</h2>

<p>By design, containers are immutable and ephemeral. A design principle is never to change running containers. Changes are made, new containers built, and the container redeployed.</p>

<p>Ideally the container should not contain the unique data mixed in with the app binaries: databases or other unique data. &#8220;Seperation of concerns&#8221;.</p>

<p>Containers seen thus far were persistent by default: changes introduced to them were kept across restarts and reboots, until the container was removed. Removal removes the UFS.</p>

<p>The two ways to persist data:</p>

<ol start="1">
<li>Volumes: a configuration option for a container that creates a special location outside of the container&#39;s Union File System (UFS) to store unique data. It persists across container removals and allows us to attach it to whatever container we want. The container just sees a filepath.</li>
<li>Bind Mounts: mounting a host dir &#47; file directly into a container; container is unaware.</li>
</ol>

<hr/>

<p>Any files put into a volume created, e.g., via the Dockerfile, will outlive that container. Requires manual deletion. The volume is created in the Dockerfile; an example drawn from the mysql Dockerfile is: <code>VOLUME &#47;var&#47;lib&#47;mysql</code>.</p>

<p>The running container gets its own unique location on the host for the volume. In the background it&#39;s mapped &#47; mounted to a location in the container. Using <code>docker container inspect</code> we can see the mounts, and each&#39;s source (on host) and destination (in container).</p>

<p>Thus, from the container&#39;s perspective we can see what volume it is using; but, from the volume&#39;s perspective we can&#39;t see what it&#39;s connected to.</p>

<hr/>

<p>Video workflow:</p>

<ul>
<li><code>docker pull mysql</code></li>
<li><code>docker image inspect mysql</code>: looking at the path included in the config for the volume destination</li>
<li><code>docker container run -d --name mysql -e MYSQL_ALLOW_EMPTY_PASSWORD=True mysql</code></li>
<li><code>docker container ls</code></li>
<li><code>docker container inspect mysql</code>: see the volume config &#38; the mounts (source and destination paths)</li>
<li><code>docker volume ls</code>: list volumes</li>
<li><code>docker volume inspect TAB COMPLETION</code>: where tab completion is the first few chars of a Volume Name (via the <code>volume ls</code>)</li>
<li><code>docker container run -d --name2 mysql -e MYSQL_ALLOW_EMPTY_PASSWORD=True mysql</code></li>
<li><code>docker volume ls</code></li>
<li><code>docker container stop mysql</code></li>
<li><code>docker container stop mysql2</code></li>
<li><code>docker container ls</code></li>
<li><code>docker container ls -a</code></li>
<li><code>docker volume ls</code></li>
<li><code>docker container rm mysql mysql2</code></li>
<li><code>docker volume ls</code></li>
<li><code>docker container run -d --name mysql -e MYSQL_ALLOW_EMPTY_PASSWORD=True -v mysql-db:&#47;var&#47;lib&#47;mysql mysql</code></li>
<li><code>docker volume ls</code></li>
<li><code>docker volume inspect mysql-db</code></li>
<li><code>docker container rm -f mysql</code></li>
</ul>

<h3 id="Named%20Volumes">Named Volumes</h3>

<p>When running a container (<code>docker container run</code>), the <code>-v</code> option allows us to:</p>

<ol start="1">
<li>Specify a new volume we want to create for the container

<ul>
<li>Case: <code>--volume &#47;path&#47;in&#47;container</code>. Docker:

<ul>
<li>creates an &#8220;anonymous&#8221; (randomly named) volume</li>
<li>copies any files and folders that are at <code>&#47;foo&#47;bar</code> inside the container to the volume when the container is started</li>
<li>bind-mounts that volume at <code>&#47;path&#47;in&#47;container</code> in the container</li>
</ul></li>
</ul></li>
<li>Create a named volume <code>-v mysql-db:&#47;var&#47;lib&#47;mysql</code>

<ul>
<li>Name: mysql-db</li>
<li>Where to create: &#47;var&#47;lib&#47;mysql (am as default, here)

<ul>
<li>Docker checks if a volume called mysql-db exists</li>
<li>If it doesn&#39;t exist, it creates it</li>
<li>If it does exist (e.g. a previous container that used it is deleted, but the volume hasn&#39;t been manually deleted), it is attached to the new container.</li>
<li>If the volume is empty (i.e. first time it&#39;s used), Docker copies any files and folders that are at <code>path&#47;in&#47;container</code> inside the container to the volume</li>
<li>Docker bind-mounts that volume at <code>&#47;path&#47;in&#47;container</code></li>
</ul></li>
<li>Equivalent to the specification in the Dockerfile, but named.

<ul>
<li>The name of an volume cannot be defined in the Dockerfile, because it is something that should be defined at runtime. If it were implemented it would entail that only one instance of the image could be run.</li>
<li>Similarly, the Dockerfile is not allowed to specify a host-path. Not only would this result in the same problem as mentioned above, it would be a security issue.</li>
</ul></li>
</ul></li>
<li>Bind Mounting

<ul>
<li>A mapping of host file &#47; dir to a container file &#47; dir (two locations pointing to the same file(s) on disk)</li>
<li><code>--volume &#47;path&#47;on&#47;host:&#47;path&#47;in&#47;container</code> How:

<ul>
<li>Docker looks for <code>&#47;path&#47;on&#47;host</code> on the host that the daemon runs</li>
<li>if <code>&#47;path&#47;on&#47;host</code> doesn&#39;t exist, creates an empty directory</li>
<li>bind-mounts <code>&#47;path&#47;on&#47;host</code> at <code>&#47;path&#47;in&#47;container</code> in the container</li>
</ul></li>
<li>Data is not copied from the container to <code>&#47;path&#47;on&#47;host</code>; files on host are leading, even if that dir is empty.

<ul>
<li>If <code>&#47;path&#47;in&#47;container</code> exists and has content, it is obscured for the duration of the bind mount, and present after the bind mount is unmounted.</li>
</ul></li>
<li>Cannot be used in Dockerfile (<code>container run</code> only), because the mounts are host specific and require specific data on the HD of the host.</li>
</ul></li>
</ol>

<p><strong>Note</strong>: you don&#39;t even have to set VOLUME in the Dockerfile, unless it&#39;s an absolute requirement for your image to have a volume at a specific location.</p>

<p><strong>Note</strong>: Use <code>docker volume create</code> before <code>docker run</code> to use custom drivers and labels</p>

<p>Above (i.e. <code>create</code>) is required before <code>docker run</code> to use custom drivers and labels.</p>

<h3 id="If%20I%20store%20database%20or%20other%20persistent%20data%20in%20a%20volume%20(or%20a%20bind%20mount).%20How%20should%20I%20back%20it%20up?">If I store database or other persistent data in a volume (or a bind mount). How should I back it up?</h3>

<p>This topic is both simple and complex.</p>

<p>The simple answer is if you have unique data that is stored after container is started, then that data should be in a volume (prefered) or a bind-mount to host (if necessary). Then the data is easily accessible from host (volumes are stored in <code>&#47;var&#47;lib&#47;docker&#47;volumes</code> by default) so then you would use whatever method you used before containers to backup that data (file copy, upload utility, etc).</p>

<p>The complex answer is that most often this data is databases and logs for images like mysql, postgres, mongodb, etc.  So, how did you backup that data before containers?  Maybe you ran a cron job that ran <code>pg_dump</code>  or <code>mysqldump</code> , so then now you would either run a cron job on host that kicks off a docker command like <code>docker container run --rm -v:&#47;path&#47;on&#47;host:&#47;path&#47;in&#47;container mysql mysqldump --backupoptions &#47;path&#47;in&#47;container</code>  and then you somehow copied that off server.  A better method in my opinion is to run a docker container that runs a cron job internally, that way you have nothing specific to host, and if you need to re-create the backup job you just create a new container. All databases images I see have the backup programs included in them, so you could also run <code>docker container exec</code>  inside existing container, if that works for you.</p>

<p>In other words, Docker doesn&#39;t backup your volume data or concern itself with your backups because that data&#39;s backup method is highly dependent on what type of data it is, and how you need to treat its backup. In general use these guidelines:</p>

<ol start="1">
<li><p>Store unique (persistent) data in docker volumes.</p></li>
<li><p>Use that app&#39;s prefered way to backup data, by running a container with the backup utility and have it connect to your existing container with the persistent data. Or run with <code>exec</code> command in existing container.</p></li>
<li><p>Backup that data to a bind mount on host or shared storage where you would normally keep your backups, or have the container SCP&#47;S3&#47;cyberduck the backup over the network and never bother with copying it to host.</p></li>
<li><p>Use cron on host, or preferably in container to schedule your backups.</p></li>
<li><p>Assuming you&#39;re storing your docker logs off-server, now your backup logs will also be there since backups are running inside a container.</p></li>
</ol>

<h1 id="Section%206:%20Docker%20Compose">Section 6: Docker Compose</h1>

<p>Compose is used to configure the relationships between containers; we can save all of the <code>docker run</code> commands in a single file.</p>

<p>There are two components:</p>

<ol start="1">
<li>YAML-formatted file that describes solution options for:

<ul>
<li>containers</li>
<li>networks</li>
<li>volumes</li>
<li>images</li>
<li>env variables</li>
</ul></li>
<li>The CLI tool <em>docker-compose</em> that is used for local dev&#47;test automation, using the YAML files.</li>
</ol>

<h2 id="docker-compose.yml">docker-compose.yml</h2>

<ul>
<li>Compose YAML format has its own versions - 1, 2, 2.1, etc. - that capture what the file can have in it. It is the first line in the file.</li>
<li>As of version 1.13 these files can now be used with the Docker command line in production with Swarm.</li>
<li><em>docker-compose.yml</em> is the default filename, but any name can be used with <code>docker-compose -f</code>.</li>
</ul>

<p>Format:</p>

<pre><code class="language-yaml">version: &#39;3.1&#39;  # if no version is specified then v1 is assumed. Recommend v2 minimum

services:  # containers. same as docker run
  servicename: # a friendly name. this is also DNS name inside network
    image: # Optional if you use build:
    command: # Optional, replace the default CMD specified by the image
    environment: # Optional, same as -e in docker run
    volumes: # Optional, same as -v in docker run
  servicename2:

volumes: # Optional, same as docker volume create

networks: # Optional, same as docker network create
</code></pre>

<p>Example:</p>

<pre><code>version: &#39;2&#39;

services:

  wordpress:
    image: wordpress
    ports:
      - 8080:80
    environment:
      WORDPRESS_DB_HOST: mysql
      WORDPRESS_DB_NAME: wordpress
      WORDPRESS_DB_USER: example
      WORDPRESS_DB_PASSWORD: examplePW
    volumes:
      - .&#47;wordpress-data:&#47;var&#47;www&#47;html

  mysql:
    image: mariadb
    environment:
      MYSQL_ROOT_PASSWORD: examplerootPW
      MYSQL_DATABASE: wordpress
      MYSQL_USER: example
      MYSQL_PASSWORD: examplePW
    volumes:
      - mysql-data:&#47;var&#47;lib&#47;mysql

volumes:
  mysql-data:
</code></pre>

<p>See docker.com&#47;compose&#47;compose-file for all the options.</p>

<h2 id="Docker%20Compose%20CLI%20Tool">Docker Compose CLI Tool</h2>

<ul>
<li>Docker Compose CLI tool is a seperate binary to the Docker tool. Is bundled with MacOS and Win versions, but not Linux distros.</li>
<li>Is it <em>not</em> designed to be a production-grade tool; but it is ideal for local dev and test.</li>
<li>Two common commands:

<ul>
<li><code>docker-compose up</code>: do everything in the compose file </li>
<li><code>docker-compose down</code>: cleanup (remove containers, networks, etc.)

<ul>
<li><code>docker-compose down -v</code>: to also remove associated volumes</li>
<li><code>docker-compose down -rmi</code>: remove all images used by any service from the cache

<ul>
<li>If the image name is left out of the Compose YAML for a custom build, the built image will be given a name. These &#8220;local&#8221; builds can be cleaned up with <code>docker-compose down --rmi local</code></li>
</ul></li>
</ul></li>
</ul></li>
<li>If all your projects had a Dockerfile and a docker-compose-yml then &#8220;new dev onboarding&#8221; would be:

<ul>
<li><code>git clone github.com&#47;some&#47;software</code></li>
<li><code>docker-compose up</code></li>
</ul></li>
</ul>

<p>Docker Compose is talking to the Docker API in the background on behalf of the Docker CLI.</p>

<h2 id="Using%20Compose%20to%20Build">Using Compose to Build</h2>

<ul>
<li>Compose can build your custom images</li>
<li><code>docker-compose up</code> will build the images (only) if they are not found in the cache

<ul>
<li>If the image is changed, you will have to <code>docker-compose build</code> or <code>docker-compose up --build</code> </li>
</ul></li>
<li>Great for complex builds – e.g. with lots of, or <em>build</em> args.</li>
</ul>

<p>Example:</p>

<pre><code>version: &#39;2&#39;

# based off compose-sample-2, only we build nginx.conf into image
# uses sample HTML static site from https:&#47;&#47;startbootstrap.com&#47;themes&#47;agency&#47;

services:
  proxy:
    build:
      context: .
      dockerfile: nginx.Dockerfile
    image: nginx-custom
    ports:
      - &#39;80:80&#39;
  web:
    image: httpd
    volumes:
      - .&#47;html:&#47;usr&#47;local&#47;apache2&#47;htdocs&#47;
</code></pre>

<ul>
<li>Here, not specifying a default image for Nginx.

<ul>
<li>If <code>nginx-custom</code> is not found in the cache it is built from a specially named Dockerfile (nginx.Dockerfile).</li>
</ul></li>
<li><code>context</code> is the location of the Dockerfile (path &#47; url) for the build.

<ul>
<li>When the value is a relative path, it is interpreted as relative to the location of the Compose file.</li>
</ul></li>
<li><code>image</code> is what we want Docker to name the image once built</li>
</ul>

<p>This nginx.Dockerfile is just:</p>

<pre><code>FROM nginx:1.13

COPY nginx.conf &#47;etc&#47;nginx&#47;conf.d&#47;default.conf
</code></pre>

<p>This is an alternative to doing a bind mount to get the config in: one might do this if one wanted to continually change the config.</p>

<h1 id="Section%207:%20Swarm%20Intro%20and%20Creating%20a%203-Node%20Swarm%20CLuster">Section 7: Swarm Intro and Creating a 3-Node Swarm CLuster</h1>

<h2 id="Swarm%20Mode:%20Built-in%20Orchestration">Swarm Mode: Built-in Orchestration</h2>

<p>How:</p>

<ul>
<li>to automate container lifecycle?</li>
<li>to scale up &#47; down?</li>
<li>to ensure containers are re-created if they fail?</li>
<li>to replace containers w&#47;o downtime (&#8220;blue&#47;green deploy&#8221;)?</li>
<li>to control &#47; track where containers get started?</li>
<li>to create cross-node virtual networks?</li>
<li>to ensure that only truster servers run our containers?</li>
<li>to store secrets, keys, passwords, etc., and get them to the right containers?</li>
</ul>

<p>Swarm is a server clustering solution that brings together different OSs &#47; hosts &#47; nodes into a single manageable unit, in which the lifecycle of the containers can be orchestrated.</p>

<p>Swarm is not enabled out of the box (at time of video anyway). New commands, once enabled:</p>

<ul>
<li><code>docker swarm</code></li>
<li><code>docker node</code></li>
<li><code>docker service</code></li>
<li><code>docker stack</code></li>
<li><code>docker secret</code></li>
</ul>

<h1 id="Section%208:%20Swarm%20Basic%20Features">Section 8: Swarm Basic Features</h1>

<h1 id="Section%209:%20Swarm%20App%20Lifecycle">Section 9: Swarm App Lifecycle</h1>

<h1 id="Section%2010:%20Container%20Registrations:%20Image%20Storage%20and%20Distribution">Section 10: Container Registrations: Image Storage and Distribution</h1>

<h1 id="Section%2011:%20Docker%20in%20Production">Section 11: Docker in Production</h1>

<h2 id="Solutions%20you%20possibly%20don&amp;#39;t%20need%20when%20first%20migrating%20to%20Dockerisation:">Solutions you possibly don&#39;t need when first migrating to Dockerisation:</h2>

<ul>
<li>Fully automatic CI&#47;CD</li>
<li>DYnamic Performance Scaling</li>
<li>Containerizing all or nothing</li>
<li>Starting with persistent data

<ul>
<li>Don&#39;t make DBs the first thing that you incorporate into your swarm cluster</li>
<li>DBs are also probably not the most agile part of the infrastructure (code updates more frequently)</li>
</ul></li>
</ul>

<h2 id="Legacy%20App%20-&amp;#62;%20Containers:">Legacy App -&#62; Containers:</h2>

<ul>
<li>Code don&#39;t not necessarily need to be changed (e.g. broken into microservices)

<ul>
<li>An exception is poor-practice hardcoded env vars, IPs, host names, etc. – which need to be pulled out into Docker ENV vars.</li>
</ul></li>
<li>&#8220;12 Factor&#8221;</li>
</ul>

<h2 id="What%20to%20Focus%20on%20First:%20Dockerfiles">What to Focus on First: Dockerfiles</h2>

<ul>
<li>More important that orchestration</li>
<li>They are your new build and env documentation

<ul>
<li>Code in Ansible &#47; Puppet, shell scripts, etc., that was used for building servers: move to Dockerfile </li>
</ul></li>
<li>Study the Dockerfile and ENTRYPOINTs from Hub Officials</li>
</ul>

<h2 id="Dockerfile%20Maturity%20Model%20(it%20might%20work%20in%20dev%20but%20not%20in%20prod)">Dockerfile Maturity Model (it might work in dev but not in prod)</h2>

<ul>
<li>Make it start</li>
<li>Make it log all things to stdout&#47;stderr</li>
<li>Document the file</li>
<li>Make it work for others</li>
<li>Make it lean (image size: not the biggest issue)

<ul>
<li>Use the OS image of whatever the non-containerised app is running on to begin with</li>
<li>Remember that a big OS image is also only stored <em>once</em>, even if used multiple times.</li>
</ul></li>
<li>Make it scale: run in multiple containers at the same time.

<ul>
<li>Because something works well in one container doesn&#39;t mean that it will work in multiple with orchestration, etc. Issues of parallel, session state, etc.</li>
</ul></li>
</ul>

<h2 id="Dockerfile%20Anti-pattern:">Dockerfile Anti-pattern:</h2>

<ul>
<li>Trapping Data

<ul>
<li>Problem: Storing unique data in a container</li>
<li>Solution: Defing <code>VOLUME</code> for each location

<ul>
<li>Inc. vols for debug logs, err dump logs (that weren&#39;t put to stdout); static file uploads from users; cached files that they want to persist between app loads, etc.</li>
</ul></li>
</ul></li>
<li>&#8220;Latest&#8221;: don&#39;t use

<ul>
<li>Use specific <code>FROM</code> tags</li>
</ul></li>
<li>Leaving Default Config

<ul>
<li>Problem: not changing app defaults or blindly copying confs (e.g. php.ini, mysql.conf.d)</li>
<li>Solution: update default configs via <code>ENV</code>, <code>RUN</code>, <code>ENTRYPOINT</code></li>
<li>A better solution is actually to use the <code>ENTRYPOINT</code> script: allow you to run a command before the CMD that sets up the config scripts on the fly. Look at the official images of mysql, etc.

<ul>
<li>This avoid hardcoding env setting into the Docker build.</li>
</ul></li>
</ul></li>
<li>Environment Specific

<ul>
<li>Problem: <code>COPY</code> in env config at image build

<ul>
<li>Cites a case where someone deployed variations of an image where only the env variables were different. One per environment. Terrible for maintainability.</li>
</ul></li>
<li>Solution: Use a single Dockerfile with default ENVs and overwrite per environment with the <code>ENTRYPOINT</code> script.</li>
</ul></li>
</ul>

<h2 id="3%20Big%20Infrastructure%20Decisions">3 Big Infrastructure Decisions</h2>

<ul>
<li>Container on VM or Container on Bare Metal?

<ul>
<li>Pros and Cons to either. Use what you know.</li>
<li>As you scale, considerations go to network settings, kernel scheduling, etc.</li>
</ul></li>
<li>OS and Distributions

<ul>
<li>Docker is highly kernel and storage driver dependent.</li>
<li>Use a modern kernel.</li>
</ul></li>
<li>Container Base Distribution</li>
</ul>

<h2 id="Swarm%20Architectures">Swarm Architectures</h2>

<p>Don&#39;t keep stuff on the host, don&#39;t have a special manager node. </p>

<h2 id="Reasons%20for%20Multiple%20Swarms">Reasons for Multiple Swarms</h2>

<p>Bad Reasons:</p>

<ul>
<li>Different hardware configs &#47; OSs</li>
<li>Different subnets or security groups</li>
<li>Different availability zones</li>
<li>Security boundaries for compliance</li>
</ul>

<p>Good Reasons:</p>

<ul>
<li>Learning: run stuff on a test swarm</li>
<li>Geographical boundaries</li>
<li>Management boundaries using Docker API</li>
</ul>

<h2 id="Stacks">Stacks</h2>

<p>Example: Open Source</p>

<table>
<thead>
<tr>
<th>Layer</th>
<th>Product</th>
</tr>
</thead>

<tbody>
<tr>
<td>Swarm GUI</td>
<td>Portainer</td>
</tr>
<tr>
<td>Central Monitoring</td>
<td>Prometheus + Grafana</td>
</tr>
<tr>
<td>Central Logging</td>
<td>ELK</td>
</tr>
<tr>
<td>Layer 7 Proxy</td>
<td>Flow-Proxy &#47; Traefik</td>
</tr>
<tr>
<td>Registry</td>
<td>Docker Distribution + Portus</td>
</tr>
<tr>
<td>CI&#47;CD</td>
<td>Jenkins</td>
</tr>
<tr>
<td>Storage</td>
<td>REX-Ray</td>
</tr>
<tr>
<td>Networking</td>
<td>Docker Swarm</td>
</tr>
<tr>
<td>Orchestration</td>
<td>Docker Swarm</td>
</tr>
<tr>
<td>Runtime</td>
<td>Docker</td>
</tr>
<tr>
<td>HW&#47;OS</td>
<td>Infrakit, Terraform</td>
</tr>
</tbody>
</table>

<ul>
<li>REX-Ray orchestrates shared storage over hosts </li>
<li>Portus is a GUI on top of the free registry from Docker

<ul>
<li><code>docker pull registry</code> is Docker&#39;s official registry; if you want you own registry, not use Docker Hub.</li>
</ul></li>
<li>A Layer 7 proxy will be required for web stuff: will need to share port 80 and 443 among many containres, therefore need a reverse proxy.</li>
<li>Prometheus controls monitoring; Grafana is a GUI on top that graphs.</li>
<li>Portainer is a GUI on top of Swarm</li>
</ul>

<p>Example with SaaS:</p>

<table>
<thead>
<tr>
<th>Layer</th>
<th>Product</th>
</tr>
</thead>

<tbody>
<tr>
<td>Swarm GUI</td>
<td>Portainer</td>
</tr>
<tr>
<td>Central Monitoring</td>
<td>Librato &#47; Sysdig</td>
</tr>
<tr>
<td>Central Logging</td>
<td>Docker for AWS &#47; Azure</td>
</tr>
<tr>
<td>Layer 7 Proxy</td>
<td>Flow-Proxy &#47; Traefik</td>
</tr>
<tr>
<td>Registry</td>
<td>DOcker Hub &#47; Quay</td>
</tr>
<tr>
<td>CI&#47;CD</td>
<td>Codeship &#47; TravisCI</td>
</tr>
<tr>
<td>Storage</td>
<td>Docker for AWS &#47; Azure</td>
</tr>
<tr>
<td>Networking</td>
<td>Docker Swarm</td>
</tr>
<tr>
<td>Orchestration</td>
<td>Docker Swarm</td>
</tr>
<tr>
<td>Runtime</td>
<td>Docker</td>
</tr>
<tr>
<td>HW&#47;OS</td>
<td>Docker for AWS &#47; Azure</td>
</tr>
</tbody>
</table>

<p>Docker for AWS are how a swarm should best be run in those environments; Docker provide templates.</p>

<h1 id="Section%2012:%20The%20What%20and%20Why%20of%20Kubernetes">Section 12: The What and Why of Kubernetes</h1>

<h1 id="Section%2013:%20Kubernetes%20Install%20and%20Your%20First%20Pods">Section 13: Kubernetes Install and Your First Pods</h1>

<h1 id="Section%2014:%20Exposing%20Kubernetes%20Ports">Section 14: Exposing Kubernetes Ports</h1>

<h1 id="Section%2015:%20Kubernetes%20Management%20Techniques">Section 15: Kubernetes Management Techniques</h1>

<h1 id="Section%2016:%20Moving%20to%20Declarative%20Kubernetes%20YAML">Section 16: Moving to Declarative Kubernetes YAML</h1>

<h1 id="Section%2017:%20Your%20Next%20Steps%20and%20the%20Future%20of%20Kubernetes">Section 17: Your Next Steps and the Future of Kubernetes</h1>

<h1 id="Section%2018:%20Docker%20Security%20Good%20Defaults%20and%20Tools">Section 18: Docker Security Good Defaults and Tools</h1>

<h1 id="Section%2019:%20Docker%2019.03%20Release:%20New%20Features">Section 19: Docker 19.03 Release: New Features</h1>

<h1 id="Section%2020:%20DevOps%20and%20Docker%20Clips">Section 20: DevOps and Docker Clips</h1>

<h2 id="Alpine%20Base%20Images&amp;#8217;%20Security">Alpine Base Images&#8217; Security</h2>

<p>Images – as the blueprints for containers – are excellent ways to scan for known vulnerabilities with the software it packages, those packages&#8217; dependencies, etc.</p>

<p>Different base images (Debian, Alpine, RHEL, etc.) allow, don&#39;t allow, or allow to varying degrees scanning programs to access where on that base OS certain packages, SSL certs, etc., are.</p>

<p>Because disk space is cheap, it is not worth using Alpine in production over Centos, Debian, etc.</p>

<p>There are a few problems with Alpine (lecture is from 2018):</p>

<ul>
<li>Can&#39;t be security scanned</li>
<li>Sometimes unexpected problems running with software.</li>
<li>Alpine package manager is different, and it doesn&#39;t have all the packages.</li>
</ul>

<p>However, because Alpine has less to it, it is more secure: less potential vulnerabilities.</p>

<h2 id="Dealing%20with%20Non-root%20Users%20in%20Containers%20and%20File%20Permissions">Dealing with Non-root Users in Containers and File Permissions</h2>

<ul>
<li><p>Bind mounts combine the permissions of the host files with those things running in the container which can often lead to frustrations. Example: when multi-server file storage is needed for multiple containers on different hosts, which all access the same files with the right permissions and also using least-privilege non-admin users.</p></li>
<li><p>When building images, <code>USER</code> is the best practice for using Dockerfile lines.</p></li>
<li><p>If inside a <code>RUN</code> command and you need to change permissions at a point of that command, <code>gosu</code> makes sense.</p></li>
<li><p>A lot of the problem can be solved with <code>chown</code> and <code>chmod</code>. For example, inside the Dockerfile <code>COPY</code> and <code>ADD</code> commands the <code>chown</code> option can be copied in with updated ownership params; meaning subsequent <code>chmod</code>s aren&#39;t required.</p></li>
<li><p>If permissions of dirs need to be changed at runtime (e.g. a volume set to certain permissions), this is what an <em>entrypoint</em> script is used for.</p>

<ul>
<li>This script, however, is run as the user set in the Dockerfile.</li>
</ul></li>
</ul>

<h2 id="Apache%20Web%20Server%20Design:%20Many%20Sites%20In%20One%20Container,%20or%20Many%20Containers?">Apache Web Server Design: Many Sites In One Container, or Many Containers?</h2>

<p>Apache servers have the ability to run many websites from one daemon. Should this option in a single container be chosen over having multiple containers?</p>

<p>Especially with orchestration, his preference is always having more containers. Yes, this is more inefficient due to multiple daemons, but it is clearer (e.g. a repo per container image, 1:1 relationship) and more flexible:</p>

<ul>
<li>containers can be scaled independently &#47; replicated for redundancy</li>
<li>if one of the websites needs to be updated, this containerised web server alone needs to be restarted rather than bringing down and back up all websites.</li>
</ul>

<p>The case may be different for DBs, due to efficiency considerations.</p>

<h2 id="Docker%20Network%20IP%20Subnet%20Conflicts%20with%20Outside%20Networks">Docker Network IP Subnet Conflicts with Outside Networks</h2>

<p>The default network driver is Bridge; for Swarm the default is Overlay. Bridge is &#8220;probably not going to be what you use in production&#8221;. </p>

<p>There can&#39;t be any subnet clashing anywhere. Even though Docker subnets are NAT-ed this is not going to help solve problems getting packets outs, if there is an overlap of subnets (NAT will redirect packets in, but a container attempting to send to an external network whose IP overlaps will just think that address is on its own local network).</p>

<p>Steps to avoid &#47; solutions:</p>

<ul>
<li>Test: create containers and try to ping something on your network (i.e. server outside docker network). Use ping, traceroute, etc.</li>
<li>For Cloud, e.g. AWS: with VPNs between you and AWS, will have to care about the AWS subnets and potential clashes.</li>
<li>Change Docker default subnets (and possibly other setting in the daemon config based on whether using Swarm Overlay, Bridge, etc.) </li>
</ul>

<h2 id="Raspberry%20Pi%20Dev%20in%20Docker">Raspberry Pi Dev in Docker</h2>

<ul>
<li>ARM architecture software can be run and tested on local Docker containers before being sent over to the Rpi. Build image locally, send to registry, pull from Rpi.

<ul>
<li>This is done with QEMU in Docker, which comes with the Desktop Edition: an emulator that allows you to run various architectures and processors.</li>
</ul></li>
</ul>

<p>See alexellis.io</p>

<h2 id="Windows%2010%20Containers%20Get%20Process%20Isolation">Windows 10 Containers Get Process Isolation</h2>

<h2 id="Should%20You%20Move%20Postgres%20to%20Containers?">Should You Move Postgres to Containers?</h2>

<h2 id="Using%20Supervisor%20to%20Run%20Multiple%20Apps%20in%20a%20Container">Using Supervisor to Run Multiple Apps in a Container</h2>

<h2 id="Should%20You%20Use%20Docker%20Compose%20or%20Swarm%20For%20a%20Single%20Server?">Should You Use Docker Compose or Swarm For a Single Server?</h2>

<p>Docker with Compose or Single Node Swarm?</p>

<p>Positives of Swarm in Production:</p>

<ul>
<li>The main reason is that you can&#39;t do rolling updates without downtime with Docker Compose.

<ul>
<li>&#8220;Swarm&#39;s <code>docker service update</code> command (which is also used by <code>docker stack deploy</code> when updating yaml changes) has TONS of options for controlling how you replace containers during an update. If you&#39;re running your own code on a Swarm, updates will be often, so you want to make sure the process is smooth, depends on healthchecks for being &#8220;ready&#8221;, maybe starts a new one first before turning off old container, and rolls back if there&#39;s a problem. None of that happens without Swarm&#39;s orchestration and scheduling.&#8221;</li>
</ul></li>
<li>Only a single command is needed to create a Swarm from a docker host: <code>docker swarm init</code></li>
<li>&#8220;You get a lot of extra features out-of-the-box with Swarm, including secrets, configs, auto-recovery of serivces, rollbacks, and healtchecks.&#8221;</li>
<li>&#8220;Healthchecks, healthchecks, healthchecks. <code>docker run</code> and <code>docker-compose</code> won&#39;t re-create containers that failed a built-in healthcheck. You only get that with Swarm, and you always want healthchecks in production on all containers.&#8221;</li>
<li>High Availability<br/>

<ul>
<li>&#8220;Just add two more nodes to a well-connected network with the 1st node. Ensure firewall ports are open between them. Then use <code>docker swarm join-token manager</code> on 1st node and run that output on 2nd&#47;3rd. Now you have a fully redundant raft log and managers. Then you can change your compose file for multiple replicas of each of your services and re-apply with <code>docker stack deploy</code> again and you&#39;re playin&#8217; with the big dogs!&#8221; </li>
</ul></li>
</ul>

<p>Local docker-compose for development works great in the workflow of getting those yaml files into production Swarm servers. Docker and Swarm are the same daemon, so no need to worry about version compatibility of production tools. Swarm isn&#39;t going to suddenly make your single production server more complex to manage and maintain.</p>

<p>Negatives of Compose in Production:</p>

<ul>
<li>It doesn&#39;t do well on reboots. docker-compose is really just a wrapper around the Docker API, so once it has started something in the detached background, it is no longer running as a separate process. One issue with this is if Docker restarts those containers that were created via YAML, docker doesn&#39;t know about any YAML changes or any env var changes that would be pulled into that YAML.</li>
<li>It can&#39;t monitor your containers with healthchecks or do anything if there is a problem.</li>
<li>It can&#39;t use encrypted secrets.</li>
<li>???: &#8220;Requires pip install or manual updates. No yum&#47;apt packages.&#8221;</li>
</ul>

<h2 id="Docker%20Env%20Configs,%20Variables,%20Entrypoints">Docker Env Configs, Variables, Entrypoints</h2>

<h2 id="Java%20and%20JBoss%20in%20Containers:%20One%20.war%20File%20Per%20Container?">Java and JBoss in Containers: One .war File Per Container?</h2>

<h2 id="TLS%20in%20Dev%20and%20Prod%20with%20Docker">TLS in Dev and Prod with Docker</h2>

<h2 id="Multiple%20Docker%20Images%20From%20One%20Git%20Repo">Multiple Docker Images From One Git Repo</h2>

<h2 id="Docker%20+%20ARM:%20Using%20RPi%20or%20AWS%20A1%20Instances%20with%20Docker">Docker + ARM: Using RPi or AWS A1 Instances with Docker</h2>

<h2 id="Docker%20and%20Swarm%20RBAC%20Options">Docker and Swarm RBAC Options</h2>

<h2 id="ENTRYPOINT%20vs.%20CMD:%20What&amp;#39;s%20the%20Difference">ENTRYPOINT vs. CMD: What&#39;s the Difference</h2>

<p>The <code>ENTRYPOINT</code> and <code>CMD</code> are two parts of the same single command that Docker runs when the container starts. If the former is present, they are put together and run in one line. It need not be a bash script, but it can be. Thus, if a script is run control is then passed over to the CMD command.</p>

<p>Remember the syntax is <code>docker container run [options] [image] [cmd]</code>, and that anything placed after the [image] replaces [cmd]. </p>

<p>The end of ENTRYPOINT bash scripts have <code>exec "$@"</code> as the final line, instructing to pass the execution to the rest of the command line (i.e. that in CMD).</p>

<p><strong>NB</strong>: The ENTRYPOINT script runs <em>everytime</em> the container starts. Therefore you don&#39;t want to build something (e.g. a DB schema) that you&#39;ll subsequently be trying to recreate. </p>

<h2 id="How%20to%20Use%20External%20Storage%20in%20Docker">How to Use External Storage in Docker</h2>

<h2 id="Can%20I%20Turn%20a%20VM%20into%20a%20Container?">Can I Turn a VM into a Container?</h2>

<h2 id="Startup%20Order%20with%20Multi-Container%20Apps">Startup Order with Multi-Container Apps</h2>

<h1 id="Section%2021:%20Dockerfile%20and%20Compose%20File%20Reviews">Section 21: Dockerfile and Compose File Reviews</h1>

<h2 id="Real%20World%20PHP%20Dockerfile%20Review">Real World PHP Dockerfile Review</h2>

<h3 id="Naming">Naming</h3>

<ul>
<li>When creating your own images, it is common to version &#38;&#47; date &#38;&#47; add-commit-id to their title.

<ul>
<li>E.g. <code>php:5.6.38-apache_1810291954</code></li>
</ul></li>
</ul>

<h3 id="Layers">Layers</h3>

<p>Important to remember that stanzas create stand-alone layers. A later layer (e.g. one intended to remove or clean up some files) cannot successfully do so to an earlier layer (e.g. one which added those files).</p>

<h3 id="Package%20Versions">Package Versions</h3>

<ul>
<li>Any installed tools (e.g. git) should be hardcorded with their version.</li>
</ul>

<h3 id="ENV">ENV</h3>

<ul>
<li>Good to put env variables at the top of the file, after <code>RUN</code>.</li>
<li>Env variables can be listed one after the next with whitespace (or with line continuation (<code>\</code>))</li>
</ul>

<h3 id="RUN">RUN</h3>

<ul>
<li>One huge <code>RUN</code> line is common for optimisation:

<ul>
<li>The operations are cached together (single image layer)</li>
<li>Smaller cached stanzas will cause problems. For example: if <code>RUN apt-get update</code> is in its own, stand-alone stanza at the top of a Dockerfile, it will run the first time, but then be cached and passed over subsequently, as it won&#39;t be changed. If a later stanza runs <code>apt-get install</code>, with the intention of installing updated package versions, it will always only reference the cached configurations, and not serve its intended purpose.</li>
</ul></li>
</ul>

<h3 id="COPY%20&amp;#47;%20ADD">COPY &#47; ADD</h3>

<p>Rather than using <code>wget</code> use <code>ADD</code>.</p>

<p><code>COPY</code> is standardly used to copy files out of the repo that you&#39;re in. <code>ADD</code> does the same thing, but is standardly used when either downloading something from the internet or, when copying-in, we wish to unzip &#47; untar. </p>

<p>The downside of <code>ADD</code> is that it is a standalone stanza &#47; layer. This means that the downloaded file cannot be cleaned-up &#47; deleted. </p>

<hr/>

<p>For <code>COPY</code>, if the files being copied-in are both for the same destination directory, this can be done in one line.</p>

<p>For standard config files, if they might need to be overwritten and one is using an orchestrator (Kubernetes &#47; Swarm), the configs of the latter (e.g. Kubernetes: config-map) can be used to mount the configs at runtime so that configs aren&#39;t hardcoded into the image. For example, SSLs shouldn&#39;t be hardcoded; they should be stored in the orchestrator &#47; Docker and mounted-in at runtime (<strong>there shouldn&#39;t be anything secret in an image when it is saved</strong>). </p>

<h3 id="CMD">CMD</h3>

<p>If inheriting the CMD from another image (i.e. via <code>FROM</code>), it is still a good practice to repeat <em>that</em> CMD in the current Dockerfile for others&#8217; readability.</p>

<h1 id="Section%2022:%20Extras">Section 22: Extras</h1>

<h1 id="Techworld%20with%20Nana%20Docker%20Full%20Tutorial">Techworld with Nana Docker Full Tutorial</h1>

<h1 id="Beyond%20Course:%20Talks%20from%20Docker">Beyond Course: Talks from Docker</h1>

<h2 id="Build%20and%20Deploy%20Multi-Container%20APPs%20to%20AWS">Build and Deploy Multi-Container APPs to AWS</h2>

<h2 id="Best%20Practices%20for%20Building%20Secure%20Docker%20Images">Best Practices for Building Secure Docker Images</h2>

<h2 id="Taking%20Docker%20to%20Production:%20What%20You%20Need%20To%20Know%20and%20Decide">Taking Docker to Production: What You Need To Know and Decide</h2>

<h2 id="Thinking%20Inside%20the%20Container:%20A%20Continuous%20Delivery%20Story">Thinking Inside the Container: A Continuous Delivery Story</h2>

<h2 id="Container%20Performance%20Analysis">Container Performance Analysis</h2>

<h2 id="Creating%20Effective%20Docker%20Images">Creating Effective Docker Images</h2>

<h2 id="Dockerfile%20Best%20Practices">Dockerfile Best Practices</h2>

<h2 id="Docker%20for%20Devs">Docker for Devs</h2>

<h2 id="Docker%20for%20Ops:%20Docker%20Storage%20and%20Volumes">Docker for Ops: Docker Storage and Volumes</h2>

<h2 id="Creating%20Effective%20Images">Creating Effective Images</h2>

<h2 id="Containerized%20Micro%20Services%20on%20AWS">Containerized Micro Services on AWS</h2>

<hr/>

<p>title: Docker
author: David 
date: Oct. 2020</p>
<footer>
	<p>© 2021 David O'Dwyer</br>
	Created with <a href='https://www.romanzolotarev.com/ssg.html'>ssg5</a> and <a href='https://kristaps.bsd.lv/lowdown/'>lowdown</a>
</footer>

</body>
</html>
